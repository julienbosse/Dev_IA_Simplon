{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "64b474f71659f9be32f34132c3eef93d33d176ead871b80ca6db3fa26bc83f65"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "DATA_DIR = '/home/simplon/Documents/aclImdb'\n",
    "target_names = ['neg', 'pos']\n",
    "# On crée une liste tout les noms des sous dossier dans le dossier eron\n",
    "subfolders = ['train','test']\n",
    "\n",
    "#On crée une liste X qui contiendra tout les email\n",
    "X = []\n",
    "#On crée une liste y qui contiendra 1 si spam 0 sinon.\n",
    "y = []\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    \n",
    "    #On crée une liste de tout les fichier contenue le dossier spam de chaque sous-dossier\n",
    "    neg_files = os.listdir(os.path.join(DATA_DIR, subfolder, 'neg'))\n",
    "    for neg_file in neg_files:\n",
    "        with open(os.path.join(DATA_DIR, subfolder, 'neg', neg_file), encoding='ascii', errors='ignore') as f:\n",
    "            X.append(f.read())\n",
    "            y.append(0)\n",
    "            \n",
    "    pos_files = os.listdir(os.path.join(DATA_DIR, subfolder, 'pos'))\n",
    "    for pos_file in pos_files:\n",
    "        with open(os.path.join(DATA_DIR, subfolder, 'pos', pos_file), encoding='ascii', errors='ignore') as f:\n",
    "            X.append(f.read())\n",
    "            y.append(1)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data = pd.DataFrame()\n",
    "data[\"text\"]=X\n",
    "data[\"y\"]=y\n",
    "\n",
    "data[\"y\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    25000\n",
       "0    25000\n",
       "Name: y, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "data[\"text\"].head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    Andie McDowell is beautiful as the 40-ish woma...\n",
       "1    I was interested in the title and description ...\n",
       "2    This film was bad because there was nothing in...\n",
       "3    This movie is terrible. TERRIBLE. One of the w...\n",
       "4    Anyone who actually had the ability to sit thr...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "import re\n",
    "\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r' ',text)\n",
    "\n",
    "# retire \n",
    "def remove_things(text):\n",
    "    html=re.compile(\"[^a-zA-Z\\s']\")\n",
    "    return html.sub(' ',text)\n",
    "\n",
    "#Remove stopwords & Punctuations\n",
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x:remove_html(x))\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x:remove_things(x))\n",
    "data[\"text\"] = data[\"text\"].apply(lambda x:remove_stopwords(x))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"text\"], data[\"y\"], test_size=0.20)"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "X_train[0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"Andie McDowell beautiful ish woman whose late start serious relationship leads considerably younger man subsequenet falling long time best girldfriends Seeing gigolo gold digger sincere young man girl friends dead set terminating silly relationship go beyond call duty helping friend obviously blinded gigolo's tricky game A short succession situations absolutely ridiculous Far fetched longer covers Without unbelievable scenes may hope sweet love story Instead viewer left involuntary shaking head things happen Without giving away cliff hanger details I warn viewer high expectations film like disappointed On scale one ranks weak There much better material This one worth time\""
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "text_model = Pipeline([('count_vec', CountVectorizer(stop_words=STOPWORDS,lowercase=True)),\n",
    "                     ('tfidf_transformer', TfidfTransformer()),\n",
    "                     ('text_model', BernoulliNB())])\n",
    "\n",
    "text_model.fit(X_train, y_train)\n",
    "y_pred = text_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8507\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "text_model = Pipeline([('count_vec', CountVectorizer(stop_words=STOPWORDS,lowercase=True)),\n",
    "                     ('tfidf_transformer', TfidfTransformer()),\n",
    "                     ('text_model', MultinomialNB())])\n",
    "\n",
    "text_model.fit(X_train, y_train)\n",
    "y_pred = text_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8613\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "text_model = Pipeline([('count_vec', CountVectorizer(stop_words=STOPWORDS,lowercase=True)), \n",
    "                      ('tfidf_transformer', TfidfTransformer()),\n",
    "                      ('text_model', SGDClassifier(tol=None, loss='log'))])\n",
    "\n",
    "text_model.fit(X_train, y_train)\n",
    "y_pred = text_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.8808\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}